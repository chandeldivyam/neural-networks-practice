{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aa66065-1a7f-4c84-ad3b-defa3e83e21c",
   "metadata": {},
   "source": [
    "# Layers and Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2973cd-dd2a-45ba-b650-823bb4101b18",
   "metadata": {},
   "source": [
    "- the ResNet-152 architecture, which is wildly popular in computer vision, possesses hundreds of layers. The ResNet architecture won the 2015 ImageNet and COCO computer vision competitions\n",
    "- From a programming standpoint, a module is represented by a class. Any subclass of it must define a forward propagation method that transforms its input into output and must store any necessary parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03233d5c-d137-42d2-974c-f6b63a5e9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334dacc0-7493-4d24-b9ba-38780efcceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divyamchandel/Documents/Projects/neural-networks-practice/env/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.LazyLinear(256), nn.ReLU(), nn.LazyLinear(10))\n",
    "\n",
    "X = torch.rand(2,20)\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaebee9-3871-4851-a112-baf58b235164",
   "metadata": {},
   "source": [
    "## Custom Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c931343-77a3-4c8f-a843-a75b611b8f9f",
   "metadata": {},
   "source": [
    "<b>Functions for a module</b>\n",
    "1. Ingest input data as arguments to its forward propagation method\n",
    "2. Generate an output by having the forward propagation method return a value\n",
    "3. Calculate the gradient of its output with respect to its input, which can be accessed via its backpropagation method\n",
    "4. Store and provide access to those parameters necessary for executing the forward propagation computation\n",
    "5. Initialize model parameters as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "311b9d70-e08c-40ec-9eaa-36964730fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.LazyLinear(256)\n",
    "        self.out = nn.LazyLinear(10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff1ea12-d161-426b-8abe-2e104e58d254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divyamchandel/Documents/Projects/neural-networks-practice/env/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb48f85-bdac-4fe5-983f-cf0e8867733e",
   "metadata": {},
   "source": [
    "## Executing Forward Prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c0f26f-b68d-46b3-a272-95f1d8f9660a",
   "metadata": {},
   "source": [
    "- Lets say we want to implement some forward propagation which is custom to our needs. Or using a constant variable which is called as `constant parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c945cd4-32ba-4b8b-bd66-9ea3a1e1bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rand_weight = torch.rand((20,20))\n",
    "        self.linear = nn.LazyLinear(20)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        X = F.relu(X @ self.rand_weight + 1)\n",
    "        X = self.linear(X)\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "\n",
    "        return X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7587b089-20e9-40c4-bfe2-2ac3da85629a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divyamchandel/Documents/Projects/neural-networks-practice/env/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.0483, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "633b9029-044b-4a29-92d4-92925b6f9221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0016, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.LazyLinear(64), nn.ReLU(),\n",
    "                                 nn.LazyLinear(32), nn.ReLU())\n",
    "        self.linear = nn.LazyLinear(16)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "\n",
    "chimera = nn.Sequential(NestMLP(), nn.LazyLinear(20), FixedHiddenMLP())\n",
    "chimera(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
