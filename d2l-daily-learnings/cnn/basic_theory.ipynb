{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406058bb-280c-465e-90a0-1f15e447bbea",
   "metadata": {},
   "source": [
    "# From Fully Connected Layers to Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de6d94d-8f04-413e-b848-2018aee8dfbc",
   "metadata": {},
   "source": [
    "- Even a 1MP image will have $10^6$ input dimensions, if we have a layer with even 1000 neuron hidden layer, a fully connected layer would be $10^9$ paramters\n",
    "- Convolutional neural networks (CNNs) are one creative way that machine learning has embraced for exploiting some of the known structure in natural images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfbb352-8f8e-4e2b-964a-d25c4f382614",
   "metadata": {},
   "source": [
    "## Invariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a3350-b293-4052-a655-b537e983aa96",
   "metadata": {},
   "source": [
    "We can now make these intuitions more concrete by enumerating a few desiderata to guide our design of a neural network architecture suitable for computer vision:\n",
    "1. In the earliest layers, our network should respond similarly to the same patch, regardless of where it appears in the image. This principle is called translation invariance (or translation equivariance).\n",
    "2. The earliest layers of the network should focus on local regions, without regard for the contents of the image in distant regions. This is the locality principle. Eventually, these local representations can be aggregated to make predictions at the whole image level\n",
    "3. As we proceed, deeper layers should be able to capture longer-range features of the image, in a way similar to higher level vision in nature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab1836-bd1a-41b0-b36c-f05ac7d1cc27",
   "metadata": {},
   "source": [
    "$$\\begin{aligned} \\left[\\mathbf{H}\\right]_{i, j} &= [\\mathbf{U}]_{i, j} + \\sum_k \\sum_l[\\mathsf{W}]_{i, j, k, l}  [\\mathbf{X}]_{k, l}\\\\ &=  [\\mathbf{U}]_{i, j} +\n",
    "\\sum_a \\sum_b [\\mathsf{V}]_{i, j, a, b}  [\\mathbf{X}]_{i+a, j+b}.\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a990bc-fe7a-4d9f-aabe-059ca991b3e9",
   "metadata": {},
   "source": [
    "The above is for when we think each pixel only have 1 feature (i.e. it is monochromatic), when we consider colored images, it add anoter dimension, so each 1MP image converts to $1000\\1000*3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01dfe01-4f5c-408f-9c93-309b4032fd10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
