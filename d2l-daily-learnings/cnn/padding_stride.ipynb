{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed571c3f-33b2-4bdf-bd1b-6b29c919c0f4",
   "metadata": {},
   "source": [
    "# Padding and Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db9b6ca-8296-45ae-8019-6e951f703243",
   "metadata": {},
   "source": [
    "- Padding can increase the height and width of the output. This is needed as the corner pixels gets very little convolutions and the middle pixels gets more. If we pad the image with zeros, this could have a better result\n",
    "- Stride is the amount of pixel we move in each convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00d40b4-ceae-4c71-9a3e-00764a6d3c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dab1e3-ef42-46a9-ab28-283be8e2f324",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2919aeb-a43a-4a0c-a9d3-912e7d70fa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def comp_conv2d(conv2d, X):\n",
    "    # We are adding batch size and number of channels\n",
    "    X = X.reshape((1,1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "\n",
    "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1)\n",
    "X = torch.rand(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "166b682a-9e2d-48d4-8bd1-68f716a6b216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf7e98e-0fee-44f8-b209-c9bde10947a8",
   "metadata": {},
   "source": [
    "## Stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbd29958-0ae6-42db-9255-54d16151cc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3319e5e-721a-47af-a346-6f4316fa15f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
