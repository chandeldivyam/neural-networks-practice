{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4dffc3e-0bc3-4307-ab29-5fc8c3952fc7",
   "metadata": {},
   "source": [
    "## Softmax Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c94e2-509d-459e-b93e-6df5a941acc5",
   "metadata": {},
   "source": [
    "#### Introduction to Regression\n",
    "\n",
    "Regression is the go-to approach for *quantitative* predictions such as predicting prices, win counts, or hospital stay durations. But it's crucial to recognize the nuances within regression models. For example:\n",
    "\n",
    "- House prices are always positive and often changes are *relative* to a base price, suggesting the use of logarithmic regression.\n",
    "- Hospital stay durations are *discrete nonnegative* values, making least mean squares not the best choice. This leads to a specialized area known as *survival modeling*.\n",
    "\n",
    "#### Key Takeaway\n",
    "- Estimation is more than just minimizing squared errors.\n",
    "- Supervised learning is broader than just regression.\n",
    "\n",
    "#### Transition to Classification\n",
    "We now shift from *how much* questions to *which category* ones, focusing on **classification** problems. Examples include:\n",
    "\n",
    "- Categorizing emails as spam or not.\n",
    "- Predicting customer subscription sign-ups.\n",
    "- Identifying animals in images.\n",
    "- Recommending movies.\n",
    "- Predicting readers interest in book sections.\n",
    "\n",
    "#### Classification Types\n",
    "Classification in machine learning can mean:\n",
    "1. **Hard assignments**: Directly categorizing examples into classes.\n",
    "2. **Soft assignments**: Assessing the probability of each categorys applicability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec207e12-6063-4eb1-9571-b15a6aadc575",
   "metadata": {},
   "source": [
    "#### Classification Problem Basics\n",
    "- **Context**: Simple image classification with $2\\times2$ grayscale images.\n",
    "- **Features**: Each image has four pixel values, represented as $x_1, x_2, x_3, x_4$.\n",
    "- **Categories**: Images are categorized into \"cat\", \"chicken\", and \"dog\".\n",
    "\n",
    "#### Label Representation\n",
    "- **Natural Impulse**: Use integers $y \\in \\{1, 2, 3\\}$ for $\\{\\textrm{dog}, \\textrm{cat}, \\textrm{chicken}\\}$.\n",
    "- **Ordinal Regression**: Useful if categories have a natural ordering, like ages or stages. See [Ordinal Regression](https://en.wikipedia.org/wiki/Ordinal_regression).\n",
    "- **One-Hot Encoding**: For non-ordered classes. Example: \"cat\" $(1, 0, 0)$, \"chicken\" $(0, 1, 0)$, \"dog\" $(0, 0, 1)$.\n",
    "\n",
    "One-hot encoding is a common technique for categorical data in classification problems without natural orderings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d7e3f7-3837-4af3-9b6e-5ad3e8236bee",
   "metadata": {},
   "source": [
    "#### Multi-Output Linear Models for Classification\n",
    "- **Objective**: Estimate conditional probabilities for each class.\n",
    "- **Model Design**: Use multiple affine functions, one for each class output.\n",
    "- **Parameters**: \n",
    "  - Weights: Represented as $w$, 12 scalars for 4 features and 3 outputs.\n",
    "  - Biases: Represented as $b$, 3 scalars.\n",
    "- **Formulation**:\n",
    "  $$o_1 = x_1 w_{11} + x_2 w_{12} + x_3 w_{13} + x_4 w_{14} + b_1,$$\n",
    "  $$o_2 = x_1 w_{21} + x_2 w_{22} + x_3 w_{23} + x_4 w_{24} + b_2,$$\n",
    "  $$o_3 = x_1 w_{31} + x_2 w_{32} + x_3 w_{33} + x_4 w_{34} + b_3.$$\n",
    "\n",
    "- **Neural Network Diagram**: Softmax regression as a single-layer neural network with a fully connected layer.\n",
    "- **Vector Notation**: $\\mathbf{o} = \\mathbf{W} \\mathbf{x} + \\mathbf{b}$, with a $3 \\times 4$ weight matrix and a bias vector in $\\mathbb{R}^3$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c7020-f9f8-458d-8c49-293c998081be",
   "metadata": {},
   "source": [
    "#### Softmax Operation\n",
    "- **Problem**: Directly minimizing the difference between outputs $\\mathbf{o}$ and labels $\\mathbf{y}$ is not ideal due to lack of guarantees on outputs being probabilities.\n",
    "- **Solution**: Use the softmax function to \"squish\" outputs into a probabilistic format:\n",
    "  $$\\hat{\\mathbf{y}} = \\mathrm{softmax}(\\mathbf{o}) \\quad \\textrm{where}\\quad \\hat{y}_i = \\frac{\\exp(o_i)}{\\sum_j \\exp(o_j)}.$$\n",
    "- **History**: The softmax concept dates back to Gibbs (1902), rooted in statistical physics by Boltzmann.\n",
    "\n",
    "#### Vectorization for Efficiency\n",
    "- **Minibatch Processing**: Vectorize calculations for computational efficiency in batches.\n",
    "- **Mathematical Formulation**: \n",
    "  $$ \\mathbf{O} = \\mathbf{X} \\mathbf{W} + \\mathbf{b}, \\quad \\hat{\\mathbf{Y}} = \\mathrm{softmax}(\\mathbf{O}). $$\n",
    "\n",
    "#### Loss Function: Cross-Entropy\n",
    "- **Objective**: Maximize mapping accuracy from features $\\mathbf{x}$ to probabilities $\\mathbf{\\hat{y}}$.\n",
    "- **Method**: Maximum likelihood estimation; negative log-likelihood as the loss function.\n",
    "- **Cross-Entropy Loss**: \n",
    "  $$ l(\\mathbf{y}, \\hat{\\mathbf{y}}) = - \\sum_{j=1}^q y_j \\log \\hat{y}_j. $$\n",
    "\n",
    "#### Information Theory Context\n",
    "- **Entropy**: Quantifies information amount in data.\n",
    "- **Surprisal**: Measures unexpectedness of an event.\n",
    "- **Cross-Entropy**: Expected surprisal for an observer with subjective probabilities upon seeing actual data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af26c91b-8d18-4faa-b99b-9a910e1b0304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
