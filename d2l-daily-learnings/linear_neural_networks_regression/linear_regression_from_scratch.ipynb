{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd9a5a57-fcab-44d4-b9f4-24f082dbc5eb",
   "metadata": {},
   "source": [
    "## Linear Regression Implementation from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "944c9dda-484c-4c29-a933-ba27ab06eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from d2l import torch as d2l\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9b4e63-360e-46c1-8233-46127b643abd",
   "metadata": {},
   "source": [
    "#### Step 1: Initializing the model\n",
    "Before starting SGD, we need to initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91b225e0-56b6-4a38-b3b9-bdd430eb8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionScratch(d2l.Module):  #@save\n",
    "    def __init__(self, num_inputs, lr, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.w = torch.normal(mean=0, std=sigma, size=(num_inputs, 1), requires_grad=True)\n",
    "        self.b = torch.tensor([0.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ddb274-f49b-45bf-867e-0654411a4c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(LinearRegressionScratch)  #@save\n",
    "def forward(self, X):\n",
    "    return self.w @ X + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de793a-1d98-4605-896c-00075f46972d",
   "metadata": {},
   "source": [
    "#### Step 2: Defining the loss function\n",
    "We are using the mean squared loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1466d591-d754-4acd-8223-546c19b9f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(LinearRegressionScratch)  #@save\n",
    "def loss(self, y_hat, y):\n",
    "    l = (y_hat - y) ** 2 / 2\n",
    "    return l.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc0a858-d0d7-4ce7-bb14-ca08ef3e05c8",
   "metadata": {},
   "source": [
    "#### Step 3: Defining the optimization algorithm\n",
    "we are using minibatch SGD. The following code applies the update, given a set of parameters, a learning rate lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59c5f517-f9c7-4d7b-a074-fe3c297ceb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(d2l.HyperParameters):  #@save\n",
    "    def __init__(self, params, lr):\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            param += (-1) * param.grad * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            if param.grad is not None:\n",
    "                param.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "017b23d7-69c7-4600-85a8-9ca2dd33148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(LinearRegressionScratch)  #@save\n",
    "def configure_optimizers(self):\n",
    "    return SGD([self.w, self.b], self.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14befe45-cf79-4c1d-84cc-f4aecdabad27",
   "metadata": {},
   "source": [
    "#### Step 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9f3087e-67fc-4119-8bb7-d5ca9af397a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(d2l.Trainer)  #@save\n",
    "def prepare_batch(self, batch):\n",
    "    return batch\n",
    "\n",
    "@d2l.add_to_class(d2l.Trainer)  #@save\n",
    "def fit_epoch(self):\n",
    "    self.model.train()\n",
    "    for batch in self.train_dataloader:\n",
    "        loss = self.model.training_step(self.prepare_batch(batch))\n",
    "        self.optim.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            loss.backward()\n",
    "            if self.gradient_clip_val > 0:\n",
    "                self.clip_gradients(self.gradient_clip_val, self.model)\n",
    "            self.optim.step()\n",
    "        self.train_batch_idx += 1\n",
    "    if self.val_dataloader is None:\n",
    "        return\n",
    "    self.model.eval()\n",
    "    for batch in self.val_dataloader:\n",
    "        with torch.no_grad():\n",
    "            self.model.validation_step(self.prepare_batch(batch))\n",
    "        self.val_batch_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4f93f1-62b2-4bbf-b0d6-d59ca9173e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
